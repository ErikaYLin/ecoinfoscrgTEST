# Workflow for Updating Predictors with Missing Information

The sections below use the outputs from workflow documented in
`ModelSelection.md` and `MetaAnalysis.md` to prepare data for spatial
interpolation of predictors with missing information, which are then
used to update model selection for the SCRG meta-analysis. This includes
the following scripts:

-   Wrangling and Cleaning Data (`wranglingCleaning_kriging.R`)
-   Standardizing and Reformatting Predictors (`standardize_kriging.R`)
-   Spatial Interpolation of Predictors (`kriging_predictors.R`)
-   Pruning & Model Selection (`pruning_kriging.R`)

Additionally, the workflow borrows from the build-up/pair-down model
selection code used to identify the most parsimonious set of predictors
for the statewide model: \* Build-Up, Pair-Down Model Selection Script
(BUPD): `BUPD.R` (parallelized) or `BUPD_nonparallel.R`

The following packages are required:

-   `sf`
-   `dplyr`
-   `stringr`

The output from this workflow (e.g., beta values, model selection
outputs) can be used in downstream workflows, such as meta-analyses, as
documented in `MetaAnalysis.md`.

## Wrangling and Cleaning Data (`wranglingCleaning_kriging.R`)

The following script imports shapefile datasets that were generated from
the original ModelSelection.md`and`MetaAnalysis.md\` scripts. The
datasets for model selection were generated by the following LSSMs:

-   [Choctawhatchee Bay Living Shoreline Model
    (VIMS)](https://www.arcgis.com/home/webmap/viewer.html?webmap=9b2ef272b1af429fa38e67134ac49da3)
-   [Pensacola Bay Living Shoreline Model
    (VIMS)](https://www.arcgis.com/apps/instant/interactivelegend/index.html?appid=e9eee63681694840a5a7d8ee41f19eb6)
-   [Living Shoreline Suitability Model for Tampa Bay
    (VIMS)](https://docs.google.com/spreadsheets/d/1jZmUNlY68Eb_SUPPAjriNE0UJUHFtkh_xXRLeNGBI_g/edit?gid=0#gid=0)
-   [Shoreline Restoration Suitability Model for North Indian River and
    Mosquito
    Lagoon](https://ucfonline.maps.arcgis.com/apps/MapSeries/index.html?appid=45caa29e80e6441c8bf6f75c542860af)

As shown in `ModelSelection.md` and the original `wranglingCleaning.R`
script, certain types of columns were removed to retain only relevant
predictor and response variables. Columns containing non-predictor
metadata (e.g., those associated with the date of study or link to
materials) were removed. This script, however, retains columns
containing geometry data (e.g., those needed for GIS shapefiles) to
inform coordinates for spatial interpolation in following scripts.
Additionally, spelling checks are performed to ensure column naming is
consistent across datasets (e.g., replacing ‘widebeach’ with
‘WideBeach’), and that values within columns are correctly spelled and
formatted (e.g., replacing “YEs” with “Yes”). Some variables are
converted to binary (presence/absence) variables (e.g., replacing “Yes”
or “Y with 1 and”No” or “N” with 0).

    # For planar data
    sf::sf_use_s2(FALSE)

    # Load packages
    library(dplyr)
    library(sf)
    library(stringr)
    # library(sp)

    # Import statewide predictors for each site
    choc <- st_transform(st_read("../output/Final_Shapefile_all_data/Choctawatchee Bay/choc_predicted.shp"))
    IRL <- st_transform(st_read("../output/Final_Shapefile_all_data/Indian River Lagoon/IRL_predicted.shp"))
    pens <- st_transform(st_read("../output/Final_Shapefile_all_data/Pensacola Bay/pens_predicted.shp"))
    tampa <- st_transform(st_read("../output/Final_Shapefile_all_data/Tampa Bay/tampa_predicted.shp"))

    # Rename Erosion column due to duplicate naming
    colnames(choc)[45] <- "Erosion_1"
    colnames(IRL)[45] <- "Erosion_1"
    colnames(pens)[45] <- "Erosion_1"
    colnames(tampa)[44] <- "Erosion_1"

    # Keep full data set for convenient access
    choc_full <- choc
    IRL_full <- IRL
    pens_full <- pens
    tampa_full <- tampa


    ####################
    # REFORMAT DATA
    ####################

    # List numerical vars
    numerical_vars <- c("angle", "IT_Width", "Hab_W1",
                        "Hab_W2", "Hab_W3", "Hab_W4", "Slope", "X3_m_depth", "X5_m_depth", "Slope_4",
                        "X10th", "X20th", "X30th", "X40th", "X50th", "X60th", "X70th", "X80th",
                        "X90th", "X99th", "MANGROVE")

    # List categorical vars
    categorical_vars <- c("bnk_height", "Beach", "WideBeach", "Exposure", "bathymetry",
                          "roads", "PermStruc", "PublicRamp", "RiparianLU", "canal",
                          "SandSpit", "Structure", "offshorest", "SAV", "marsh_all",
                          "tribs", "defended", "rd_pstruc", "lowBnkStrc", "ShlType",
                          "Fetch_", "selectThis", "StrucList", "forestshl",
                          "City", "Point_Type", "Edge_Type", "Hard_Mater", "Adj_LU",
                          "Erosion_1", "Erosion_2", "Owner", "Adj_H1", "Adj_H2", "Adj_H3",
                          "Adj_H4", "V_Type1", "V_Type2", "V_Type3", "V_Type4",
                          "Rest_Opp", "X0yster_Pr", "Seagrass_P", "Hardened_1", "WTLD_VEG_3")
    # note that study column is excluded here for easier processing later

    # List binary variables
    binary_vars <- c("Beach", "WideBeach", "PublicRamp", "canal", "SandSpit", "SAV",
                     "defended", "selectThis", "Erosion_2", "Rest_Opp", "X0yster_Pr", "Seagrass_P", "Hardened_1")

    # Update list of categorical variables (no binary)
    categorical_vars2 <- setdiff(categorical_vars, binary_vars)

    # Combine data into list
    pred <- list(choc = choc, IRL = IRL, pens = pens, tampa = tampa)

    # Factorize categorical variables
    for (i in 1:length(pred)) {
      for (j in 1:ncol(pred[[i]])) {
        pred[[i]][[j]] <- gsub("NA", NA, pred[[i]][[j]])
      }
    }

    # Reconvert to site-specific sf objects
    choc <- pred$choc %>%
      st_set_geometry(choc_full$geometry) %>%
      st_as_sf()
    IRL <- pred$IRL %>%
      st_set_geometry(IRL_full$geometry) %>%
      st_as_sf()
    pens <- pred$pens %>%
      st_set_geometry(pens_full$geometry) %>%
      st_as_sf()
    tampa <- pred$tampa %>%
      st_set_geometry(tampa_full$geometry) %>%
      st_as_sf()

    # Combine Data
    state <- dplyr::bind_rows(choc, pens, tampa, IRL)
    pred <- state  %>%
      dplyr::select(-"Response") # Remove response variables

    pred <- pred %>%
      mutate(across(all_of(numerical_vars), as.numeric)) # convert them to numeric if not already
    # pred <- pred %>%
    #   mutate(across(all_of(categorical_vars), as.factor)) # convert them to factor if not already

    ##################
    # SPELL CHECK 
    ##################

    # Spelling and capitalization corrections (words needs to be chosen manually)
    corrections <- data.frame(
      incorrect = c("YEs", "no", "NO", "No'", "RIprap", "riprap", "Permament",
                    "Permanenet", "Permanenent", "Bulkead", "Bulkhea", "BUlkhead",
                    "Bulkkhead", "moderate", "Scrub-shurb", "toe",
                    "S, Shell, v", "R, s, Shell", "high", "low"),
      correct = c("Yes", "No", "No", "No", "Riprap", "Riprap", "Permanent",
                  "Permanent", "Permanent", "Bulkhead", "Bulkhead", "Bulkhead",
                  "Bulkhead", "Moderate", "Scrub-shrub", "Toe",
                  "S, Shell, V", "R, S, Shell", "High", "Low")
    )

    # Fix misspelled words
    pred <- pred %>%
      mutate(across(where(is.character), ~{
        column <- .
        for (i in 1:nrow(corrections)) {
          # for (i in seq_along(corrections$incorrect)) {
          # Use regex to match case-insensitively
          pattern <- str_c("(?i)\\b", corrections$incorrect[i], "\\b")
          column <- str_replace_all(column, regex(pattern), corrections$correct[i])
        }
        column
      }))

    # Check for additional inconsistencies in data entry
    for (var in categorical_vars) {
      print(unique(pred[[var]]))
    }

    # Fix unique cases of misspellings
    pred$Adj_H2[44059] <- "V"
    pred$WideBeach <- gsub("Yes", "1", pred$WideBeach)
    pred$PublicRamp <- gsub("Yes", "1", pred$PublicRamp)
    pred$canal <- gsub("Canal", "1", pred$canal)
    pred$canal <- gsub("No", "0", pred$canal)
    pred$SandSpit <- gsub("Yes", "1", pred$SandSpit)
    pred$SAV <- gsub("Yes", "1", pred$SAV)
    pred$SAV <- gsub("No", "0", pred$SAV)
    pred$marsh_all <- gsub("No'", "No", pred$marsh_all)
    pred$defended <- gsub("Yes", "1", pred$defended)
    pred$selectThis <- gsub("Yes", "1", pred$selectThis)
    pred$selectThis <- gsub("No", "0", pred$selectThis)
    pred$Rest_Opp <- gsub("Y", "1", pred$Rest_Opp)
    pred$Rest_Opp <- gsub("N", "0", pred$Rest_Opp)
    pred$X0yster_Pr <- gsub("Y", "1", pred$X0yster_Pr)
    pred$X0yster_Pr <- gsub("N", "0", pred$X0yster_Pr)
    pred$Seagrass_P <- gsub("Y", "1", pred$Seagrass_P)
    pred$Seagrass_P <- gsub("N", "0", pred$Seagrass_P)

## Standardizing and Reformatting Predictors (`standardize_kriging.R`)

Categorical variables are split into binary indicator variables and true
categorical variables. Previously, in the original dataset, certain
categorical variables contained locations that listed multiple
categories in a string. When converted into dummy variables, each string
would be handled as its own individual binary dummy variable; however,
as that would effectively add superfluous predictors, potentially
biasing model selection, these strings are divided before separating
such variables into factorized binary indicators. Any remaining
categorical variables are then converted to dummy variables in
preparation for model selection. Additionally, the predictors were
filtered at each study site to determine where spatial interpolation
could be used to fill in missing information.

    #########################
    # NUMERICAL VARS
    #########################
    # List numerical vars
    numerical_vars <- c("angle", "IT_Width", "Hab_W1", 
                        "Hab_W2", "Hab_W3", "Hab_W4", "Slope", "X3_m_depth", "X5_m_depth", "Slope_4",
                        "X10th", "X20th", "X30th", "X40th", "X50th", "X60th", "X70th", "X80th",
                        "X90th", "X99th", "MANGROVE")
    pred <- pred %>% 
      mutate(across(all_of(numerical_vars), as.numeric)) # convert them to numeric if not already

    # Checks
    ## make sure sd is close to 1 and mean is close to 0
    summary(pred[numerical_vars]) # summary stats
    # sapply(pred[numerical_vars], sd, na.rm = TRUE) # stdev

    #########################
    # CATEGORICAL VARS
    #########################
    # List cat vars
    categorical_vars <- c("bnk_height", "Beach", "WideBeach", "Exposure", "bathymetry", 
                          "roads", "PermStruc", "PublicRamp", "RiparianLU", "canal", 
                          "SandSpit", "Structure", "offshorest", "SAV", "marsh_all", 
                          "tribs", "defended", "rd_pstruc", "lowBnkStrc", "ShlType", 
                          "Fetch_", "selectThis", "StrucList", "forestshl", 
                          "City", "Point_Type", "Edge_Type", "Hard_Mater", "Adj_LU", 
                          "Erosion_1", "Erosion_2", "Owner", "Adj_H1", "Adj_H2", "Adj_H3", "Adj_H4", "V_Type1", 
                          "V_Type2", "V_Type3", "V_Type4", "Rest_Opp", "X0yster_Pr", "Seagrass_P",
                          "Hardened_1", "WTLD_VEG_3") 
    # note that study column is excluded here for easier processing later

    # List binary variables
    binary_vars <- c("Beach", "WideBeach", "PublicRamp", "canal", "SandSpit", "SAV", 
                     "defended", "selectThis", "Erosion_2", "Rest_Opp", "X0yster_Pr", "Seagrass_P", "Hardened_1")

    # Update list of cat vars (exclude binary)
    categorical_vars2 <- setdiff(categorical_vars, binary_vars)

    # Fix lists of categories to separate columns
    ## Identify categorical variables with string of categories
    for (var in categorical_vars2) {
      print(unique(pred[[var]]))
    }
    categorical_vars2  # Edge_Type, Hard_Mater, Adj_LU, Adj_H1, Adj_H2, Adj_H3, Adj_H4, V_Type4

    # Indicator variables to convert to dummy vars
    dummy_vars <- c("Edge_Type", "Hard_Mater", "Adj_LU", "Adj_H1",  
                    "Adj_H2", "Adj_H3", "Adj_H4", "V_Type4")


    # Edge_Type
    edgetype <- matrix(data = 0, nrow = nrow(pred),  # matrix of unique categories
                       ncol = length(unique(unlist(strsplit(as.character(pred$Edge_Type), ",")))),
                       dimnames = list(NULL, c("Edge_Type_Missing", unique(unlist(strsplit(as.character(pred$Edge_Type), ",")))[-1])))
    edgetype <- as.data.frame(edgetype)  # convert matrix to data frame
    # Convert categories to binaries
    for (i in 2:ncol(edgetype)) {  
      # Identify categories present at each observation
      edgetype[which(grepl(colnames(edgetype)[i], pred$Edge_Type)), i] <- 1
      colnames(edgetype)[i] <- paste0("Edge_Type_", i-1)
    }
    edgetype[which(is.na(pred$Edge_Type)), 1] <- 1  # find NAs
    edgetype <- edgetype %>%  # factorize all columns
      mutate(across(all_of(colnames(edgetype)), as.factor))
    pred <- cbind(pred, edgetype)  # add to predictors

    # Hard_Mater
    for (i in 1:nrow(pred)) {
      if (!is.na(pred$Hard_Mater[i])) {
        pred$Hard_Mater[i] <- paste0(pred$Hard_Mater[i], ".")  # add "." to each string
      }
    }
    pred$Hard_Mater <- gsub(",", ".,", pred$Hard_Mater)  # add "." to each category in string

    hardmater <- matrix(data = 0, nrow = nrow(pred),  # matrix of unique categories
                        ncol = length(unique(unlist(strsplit(as.character(pred$Hard_Mater), ", ")))),
                        dimnames = list(NULL, c("Hard_Mater_Missing", unique(unlist(strsplit(as.character(pred$Hard_Mater), ", ")))[-1])))
    hardmater <- as.data.frame(hardmater)  # convert matrix to data frame
    # Convert categories to binaries
    for (i in 2:ncol(hardmater)) {  
      # Identify categories present at each observation
      hardmater[which(grepl(colnames(hardmater)[i], pred$Hard_Mater, fixed = TRUE)), i] <- 1
      colnames(hardmater)[i] <- paste0("Hard_Mater_", i-1)
    }
    hardmater[which(is.na(pred$Hard_Mater)), 1] <- 1  # find NAs
    hardmater <- hardmater %>%  # factorize all columns
      mutate(across(all_of(colnames(hardmater)), as.factor))
    pred <- cbind(pred, hardmater)  # add to predictors

    # Adj_LU
    for (i in 1:nrow(pred)) {
      if (!is.na(pred$Adj_LU[i])) {
        pred$Adj_LU[i] <- paste0(pred$Adj_LU[i], ".")  # add "." to each string
      }
    }
    pred$Adj_LU <- gsub(",", ".,", pred$Adj_LU)  # add "." to each category in string

    adj_lu <- matrix(data = 0, nrow = nrow(pred),  # matrix of unique categories
                     ncol = length(unique(unlist(strsplit(as.character(pred$Adj_LU), ", ")))),
                     dimnames = list(NULL, c("Adj_LU_Missing", unique(unlist(strsplit(as.character(pred$Adj_LU), ", ")))[-1])))
    adj_lu <- as.data.frame(adj_lu)  # convert matrix to data frame
    # Convert categories to binaries
    for (i in 2:ncol(adj_lu)) {  
      # Identify categories present at each observation
      adj_lu[which(grepl(colnames(adj_lu)[i], pred$Adj_LU, fixed = TRUE)), i] <- 1
      colnames(adj_lu)[i] <- paste0("Adj_LU_", i-1)
    }
    adj_lu[which(is.na(pred$Adj_LU)), 1] <- 1  # find NAs
    adj_lu <- adj_lu %>%  # factorize all columns
      mutate(across(all_of(colnames(adj_lu)), as.factor))
    pred <- cbind(pred, adj_lu)  # add to predictors

    # Adj_H1
    for (i in 1:nrow(pred)) {
      if (!is.na(pred$Adj_H1[i])) {
        pred$Adj_H1[i] <- paste0(pred$Adj_H1[i], ".")  # add "." to each string
      }
    }
    pred$Adj_H1 <- gsub(",", ".,", pred$Adj_H1)  # add "." to each category in string

    adj_h1 <- matrix(data = 0, nrow = nrow(pred),  # matrix of unique categories
                     ncol = length(unique(unlist(strsplit(as.character(pred$Adj_H1), ", ")))),
                     dimnames = list(NULL, c("Adj_H1_Missing", unique(unlist(strsplit(as.character(pred$Adj_H1), ", ")))[-1])))
    adj_h1 <- as.data.frame(adj_h1)  # convert matrix to data frame
    # Convert categories to binaries
    for (i in 2:ncol(adj_h1)) {  
      # Identify categories present at each observation
      adj_h1[which(grepl(colnames(adj_h1)[i], pred$Adj_H1, fixed = TRUE)), i] <- 1
      colnames(adj_h1)[i] <- paste0("Adj_H1_", i-1)
    }
    adj_h1[which(is.na(pred$Adj_H1)), 1] <- 1  # find NAs
    adj_h1 <- adj_h1 %>%  # factorize all columns
      mutate(across(all_of(colnames(adj_h1)), as.factor))
    pred <- cbind(pred, adj_h1)  # add to predictors

    # Adj_H2
    for (i in 1:nrow(pred)) {
      if (!is.na(pred$Adj_H2[i])) {
        pred$Adj_H2[i] <- paste0(pred$Adj_H2[i], ".")  # add "." to each string
      }
    }
    pred$Adj_H2 <- gsub(",", ".,", pred$Adj_H2)  # add "." to each category in string

    adj_h2 <- matrix(data = 0, nrow = nrow(pred),  # matrix of unique categories
                     ncol = length(unique(unlist(strsplit(as.character(pred$Adj_H2), ", ")))),
                     dimnames = list(NULL, c("Adj_H2_Missing", unique(unlist(strsplit(as.character(pred$Adj_H2), ", ")))[-1])))
    adj_h2 <- as.data.frame(adj_h2)  # convert matrix to data frame
    # Convert categories to binaries
    for (i in 2:ncol(adj_h2)) {  
      # Identify categories present at each observation
      adj_h2[which(grepl(colnames(adj_h2)[i], pred$Adj_H2, fixed = TRUE)), i] <- 1
      colnames(adj_h2)[i] <- paste0("Adj_H2_", i-1)
    }
    adj_h2[which(is.na(pred$Adj_H2)), 1] <- 1  # find NAs
    adj_h2 <- adj_h2 %>%  # factorize all columns
      mutate(across(all_of(colnames(adj_h2)), as.factor))
    pred <- cbind(pred, adj_h2)  # add to predictors

    # Adj_H3
    for (i in 1:nrow(pred)) {
      if (!is.na(pred$Adj_H3[i])) {
        pred$Adj_H3[i] <- paste0(pred$Adj_H3[i], ".")  # add "." to each string
      }
    }
    pred$Adj_H3 <- gsub(",", ".,", pred$Adj_H3)  # add "." to each category in string

    adj_h3 <- matrix(data = 0, nrow = nrow(pred),  # matrix of unique categories
                     ncol = length(unique(unlist(strsplit(as.character(pred$Adj_H3), ", ")))),
                     dimnames = list(NULL, c("Adj_H3_Missing", unique(unlist(strsplit(as.character(pred$Adj_H3), ", ")))[-1])))
    adj_h3 <- as.data.frame(adj_h3)  # convert matrix to data frame
    # Convert categories to binaries
    for (i in 2:ncol(adj_h3)) {  
      # Identify categories present at each observation
      adj_h3[which(grepl(colnames(adj_h3)[i], pred$Adj_H3, fixed = TRUE)), i] <- 1
      colnames(adj_h3)[i] <- paste0("Adj_H3_", i-1)
    }
    adj_h3[which(is.na(pred$Adj_H3)), 1] <- 1  # find NAs
    adj_h3 <- adj_h3 %>%  # factorize all columns
      mutate(across(all_of(colnames(adj_h3)), as.factor))
    pred <- cbind(pred, adj_h3)  # add to predictors

    # Adj_H4
    for (i in 1:nrow(pred)) {
      if (!is.na(pred$Adj_H4[i])) {
        pred$Adj_H4[i] <- paste0(pred$Adj_H4[i], ".")  # add "." to each string
      }
    }
    pred$Adj_H4 <- gsub(",", ".,", pred$Adj_H4)  # add "." to each category in string

    adj_h4 <- matrix(data = 0, nrow = nrow(pred),  # matrix of unique categories
                     ncol = length(unique(unlist(strsplit(as.character(pred$Adj_H4), ", ")))),
                     dimnames = list(NULL, c("Adj_H4_Missing", unique(unlist(strsplit(as.character(pred$Adj_H4), ", ")))[-1])))
    adj_h4 <- as.data.frame(adj_h4)  # convert matrix to data frame
    # Convert categories to binaries
    for (i in 2:ncol(adj_h4)) {  
      # Identify categories present at each observation
      adj_h4[which(grepl(colnames(adj_h4)[i], pred$Adj_H4, fixed = TRUE)), i] <- 1
      colnames(adj_h4)[i] <- paste0("Adj_H4_", i-1)
    }
    adj_h4[which(is.na(pred$Adj_H4)), 1] <- 1  # find NAs
    adj_h4 <- adj_h4 %>%  # factorize all columns
      mutate(across(all_of(colnames(adj_h4)), as.factor))
    pred <- cbind(pred, adj_h4)  # add to predictors

    # V_Type4
    for (i in 1:nrow(pred)) {
      if (!is.na(pred$V_Type4[i])) {
        pred$V_Type4[i] <- paste0(pred$V_Type4[i], ".")  # add "." to each string
      }
    }
    pred$V_Type4 <- gsub(",", ".,", pred$V_Type4)  # add "." to each category in string

    v_type4 <- matrix(data = 0, nrow = nrow(pred),  # matrix of unique categories
                      ncol = length(unique(unlist(strsplit(as.character(pred$V_Type4), ", ")))),
                      dimnames = list(NULL, c("V_Type4_Missing", unique(unlist(strsplit(as.character(pred$V_Type4), ", ")))[-1])))
    v_type4 <- as.data.frame(v_type4)  # convert matrix to data frame
    # Convert categories to binaries
    for (i in 2:ncol(v_type4)) {  
      # Identify categories present at each observation
      v_type4[which(grepl(colnames(v_type4)[i], pred$V_Type4, fixed = TRUE)), i] <- 1
      colnames(v_type4)[i] <- paste0("V_Type4_", i-1)
    }
    v_type4[which(is.na(pred$V_Type4)), 1] <- 1  # find NAs
    v_type4 <- v_type4 %>%  # factorize all columns
      mutate(across(all_of(colnames(v_type4)), as.factor))
    pred <- cbind(pred, v_type4)  # add to predictors


    pred <- pred %>% 
      mutate(across(all_of(categorical_vars), as.factor)) # convert them to factor if not already


    ############################################
    # VARS WITH MISSING INFORMATION
    ############################################
    ## Auto-kriging will be used to interpolate for variables where possible

    # Site names
    site <- c("choc", "IRL", "pens", "tampa")
    pred2 <- as.data.frame(pred)

    # List to store numerical variables with missing data
    miss_num <- list()

    # For each numerical variable, check for NAs
    for (i in site) {
      for (var in numerical_vars) {
        # No info for entire site
        if (all(is.na(pred2[pred2$study == i, var]))) {
          miss_num[[i]]$statewide[[var]] <- var
          # Some info missing at site
        } else if (any(is.na(pred2[pred2$study == i, var]))) {
          miss_num[[i]]$sitewide[[var]] <- var
        }
      }
    }

    # List to store binary variables with missing data
    miss_bin <- list()

    # For each categorical variable, check for NAs
    for (var in binary_vars) {
      for (i in site) {
        # No info for entire site
        if (all(is.na(pred2[pred2$study == i, var]))) {
          miss_bin[[i]]$statewide[[var]] <- var
          # Some info missing at site
        } else if (any(is.na(pred2[pred2$study == i, var]))) {
          miss_bin[[i]]$sitewide[[var]] <- var
        }
      }
    }

    # List to store categorical variables with missing data
    miss_cat <- list()

    # For each categorical variable, check for NAs
    for (var in categorical_vars2) {
      for (i in site) {
        # No info for entire site
        if (all(is.na(pred2[pred2$study == i, var]))) {
          miss_cat[[i]]$statewide[[var]] <- var
          # Some info missing at site
        } else if (any(is.na(pred2[pred2$study == i, var]))) {
          miss_cat[[i]]$sitewide[[var]] <- var
        }
      }
    }


    #########################
    # DUMMY VARS
    #########################

    # Variables to convert to dummy vars
    categorical_vars3 <- setdiff(categorical_vars2, dummy_vars)

    # Replace NA with "Missing" for dummy vars
    pred <- pred %>%
      mutate(across(all_of(categorical_vars3), ~ factor(ifelse(is.na(.), "Missing", .),
                                                        levels = unique(c(.,"Missing")))))

    # Drop geometry for dummy encoding
    geom <- pred$geometry  # save geometry separately
    pred <- st_drop_geometry(pred)  

    # Make dummy vars for all
    for (var in categorical_vars3) {
      dummies <- model.matrix(~ . - 1, data = pred[var])  # suggested to avoid intercept
      colnames(dummies) <- paste(var, levels(pred[[var]]), sep = "_")
      pred <- cbind(pred, as.data.frame(dummies))
    }

    # Save columns with "Missing"
    miss_data <- pred %>%
      dplyr::select(c(contains("Missing"), study)) %>%
      mutate(across(all_of(contains("Missing")), as.factor)) %>%
      mutate(geometry = geom)
    miss_data <- st_as_sf(miss_data)  # convert to spatial object

    # Separate sites for missing data
    miss_choc <- miss_data[miss_data$study == "choc",]
    miss_IRL <- miss_data[miss_data$study == "IRL",]
    miss_pens <- miss_data[miss_data$study == "pens",]
    miss_tampa <- miss_data[miss_data$study == "tampa",]

    # Remove OG categorical columns
    pred <- pred %>%
      dplyr::select(-all_of(categorical_vars2)) %>%
      dplyr::select(-contains(c("Length", "Lgth"))) %>%  # remove "Length" columns
      dplyr::select(-contains("Missing"))  # remove columns with "Missing"

    # Remove spatial data artifacts
    pred <- pred %>%
      dplyr::select(-c("feature_x", "feature_y", "nearest_x", "nearest_y", "Shape__Len",
                       "field_84", "distance_2", "field_83"))

    # Reset geometry for predictors
    st_geometry(pred) <- geom
    pred <- st_as_sf(pred)

    # Check data
    str(pred)

    # Separate data by study site
    choc <- pred[pred$study == "choc",]
    IRL <- pred[pred$study == "IRL",]
    pens <- pred[pred$study == "pens",]
    tampa <- pred[pred$study == "tampa",]

## Spatial Interpolation of Predictors (`kriging_predictors.R`)

Numerical and indicator variables with missing information are
interpolated using a geostatistical technique, auto-Kriging (Cressie,
1993), that calculates for point estimates of variables based on the
spatial autocorrelation of data. The `automap` package was used to
automate the Kriging process and select the best fit autocorrelation
model to the data. For variables that were uniform at specific sites,
missing values were filled to match the known values. The “angle”
variable was transformed such that all angles fell within the range of
\[0,90\] and the resulting predictors were saved both with and without
the angle transformation.

Categorical variables require extensive time to Krige and categorical
data at locations were insufficiently autocorrelated to produce
meaningful results. As such, interpolation results for categorical
predictors are not incorporated into the data input for model selection.
Furthermore, co-Kriging could not be used to interpolate for categorical
and numerical variables with widely absent data (missing information for
entire study sites), as there was little to no correlation between
predictors and additional variables with widespread data collection
(e.g., bathymetry and coastal relief).

    ############################
    # SITEWIDE INTERPOLATION
    ############################

    # `automap::autoKrige()` used for automated interpolation at specific sites

    # Prepare spatial data
    crs <- sp::CRS("EPSG:6346")  # retrieve coordinate reference system

    ## NUMERICAL VARS ----

    # Function for interpolating numerical and binary vars
    site_num <- function(site, var, formula, duplicates = TRUE) {

      # Select variable to krige for
      num.var <- as.data.frame(dplyr::select(site, var))  # automatically selects geometry
      newdat <- num.var[is.na(num.var[var]),]  # store rows where data is missing
      num.var <- num.var[!is.na(num.var[var]),]  # remove rows missing data

      # Convert to spatial object
      num.var <- sp::SpatialPointsDataFrame(coords = sf::st_coordinates(sf::st_as_sf(num.var)),
                                            data = num.var,
                                            proj4string = crs)

      # # Empirical variogram
      # variogram <- automap::autofitVariogram(var ~ 1, bin.var)
      # variogram

      # Krige for numerical/binary variable
      krige <- automap::autoKrige(as.formula(formula), num.var,
                                  new_data = sp::SpatialPointsDataFrame(sf::st_coordinates(sf::st_as_sf(newdat)),
                                                                        data = as.data.frame(newdat),
                                                                        proj4string = crs),
                                  remove_duplicates = duplicates, verbose = TRUE)
      return(krige)  # kriged output
    }


    # IRL Hab_W4
    IRL_habw4_krige <- site_num(IRL, "Hab_W4", formula = "Hab_W4 ~ 1")  # kriging for unknowns
    # saveRDS(IRL_habw4_krige, file = "../Data/Kriging_outputs/IRL_Hab_W4_krige.rds")
    IRL_habw4_krige <- readRDS(file = "../Data/Kriging_outputs/IRL_Hab_W4_krige.rds")
    IRL$Hab_W4[is.na(IRL$Hab_W4)] <- IRL_habw4_krige$krige_output$var1.pred

    # Add interpolated data to statewide predictors
    pred$Hab_W4[pred$study == "IRL"] <- IRL$Hab_W4


    ## BINARY VARS ----

    # IRL Rest_Opp
    IRL_restopp_krige <- site_num(IRL, var = "Rest_Opp", formula = "Rest_Opp ~ 1")
    # saveRDS(IRL_restopp_krige, file = "../Data/Kriging_outputs/IRL_Rest_Opp_krige.rds")
    IRL_restopp_krige <- readRDS(file = "../Data/Kriging_outputs/IRL_Rest_Opp_krige.rds")
    IRL$Rest_Opp[is.na(IRL$Rest_Opp)] <- as.factor(ifelse(IRL_restopp_krige$krige_output$var1.pred >= 1.5, 1, 0))

    # Add interpolated data to statewide predictors
    pred$Rest_Opp[pred$study == "IRL"] <- IRL$Rest_Opp

    # IRL X0yster_Pr
    IRL_oysterpr_krige <- site_num(IRL, var = "X0yster_Pr", formula = "X0yster_Pr ~ 1")
    # saveRDS(IRL_oysterpr_krige, file = "../Data/Kriging_outputs/IRL_X0yster_Pr_krige.rds")
    IRL_oysterpr_krige <- readRDS(file = "../Data/Kriging_outputs/IRL_X0yster_Pr_krige.rds")
    IRL$X0yster_Pr[is.na(IRL$X0yster_Pr)] <- as.factor(ifelse(IRL_oysterpr_krige$krige_output$var1.pred >= 1.5, 1, 0))

    # Add interpolated data to statewide predictors
    pred$X0yster_Pr[pred$study == "IRL"] <- IRL$X0yster_Pr

    # IRL Seagrass_P
    IRL_seagrass_krige <- site_num(IRL, var = "Seagrass_P", formula = "Seagrass_P ~ 1")
    # saveRDS(IRL_seagrass_krige, file = "../Data/Kriging_outputs/IRL_Seagrass_P_krige.rds")
    IRL_seagrass_krige <- readRDS(file = "../Data/Kriging_outputs/IRL_Seagrass_P_krige.rds")
    IRL$Seagrass_P[is.na(IRL$Seagrass_P)] <- as.factor(ifelse(IRL_seagrass_krige$krige_output$var1.pred >= 1.5, 1, 0))

    # Add interpolated data to statewide predictors
    pred$Seagrass_P[pred$study == "IRL"] <- IRL$Seagrass_P


    # tampa WideBeach
    # tampa_wbeach_krige <- site_num(tampa, var = "WideBeach", formula = "WideBeach ~ 1")
    ## CANNOT INTERPOLATE: All observations identical and equal to 1
    tampa$WideBeach[is.na(tampa$WideBeach)] <- 1

    # Add interpolated data to statewide predictors
    pred$WideBeach[pred$study == "tampa"] <- tampa$WideBeach

    # tampa PublicRamp
    # tampa_pramp_krige <- site_num(tampa, var = "PublicRamp", formula = "PublicRamp ~ 1")
    ## CANNOT INTERPOLATE: All observations identical and equal to 1
    tampa$PublicRamp[is.na(tampa$PublicRamp)] <- 1

    # Add interpolated data to statewide predictors
    pred$PublicRamp[pred$study == "tampa"] <- tampa$PublicRamp

    # tampa canal
    # tampa_canal_krige <- site_num(tampa, var = "canal", formula = "canal ~ 1")
    ## CANNOT INTERPOLATE: All observations identical and equal to 1
    tampa$canal[is.na(tampa$canal)] <- 1

    # Add interpolated data to statewide predictors
    pred$canal[pred$study == "tampa"] <- tampa$canal

    # tampa SandSpit
    # tampa_sandspit_krige <- site_num(tampa, var = "SandSpit", formula = "SandSpit ~ 1")
    ## CANNOT INTERPOLATE: All observations identical and equal to 1
    tampa$SandSpit[is.na(tampa$SandSpit)] <- 1

    # Add interpolated data to statewide predictors
    pred$SandSpit[pred$study == "tampa"] <- tampa$SandSpit

    # tampa SAV
    tampa_sav_krige <- site_num(tampa, var = "SAV", formula = "SAV ~ 1")
    ## CANNOT INTERPOLATE: All observations identical and equal to 1
    tampa$SAV[is.na(tampa$SAV)] <- 1

    # Add interpolated data to statewide predictors
    pred$SAV[pred$study == "tampa"] <- tampa$SAV

    # tampa defended
    tampa_def_krige <- site_num(tampa, var = "defended", formula = "defended ~ 1")
    ## CANNOT INTERPOLATE: All observations identical and equal to 1
    tampa$defended[is.na(tampa$defended)] <- 1

    # Add interpolated data to statewide predictors
    pred$defended[pred$study == "tampa"] <- tampa$defended


    # # choc canal
    # choc_canal_krige <- site_num(choc, var = "canal", formula = "canal ~ 1")

    # # choc SandSpit
    # choc_sandspit_krige <- site_num(choc, var = "SandSpit", formula = "SandSpit ~ 1")

    # choc SAV
    choc_sav_krige <- site_num(choc, var = "SAV", formula = "SAV ~ 1")
    # saveRDS(choc_sav_krige, file = "../Data/Kriging_outputs/choc_SAV_krige.rds")
    choc$SAV[is.na(choc$SAV)] <- as.factor(ifelse(choc_sav_krige$krige_output$var1.pred >= 0.5, 1, 0))
    ### GENERATES ONLY NAs

    # choc selectThis
    choc_select_krige <- site_num(choc, var = "selectThis", formula = "selectThis ~ 1")
    # saveRDS(choc_select_krige, file = "../Data/Kriging_outputs/choc_selectThis_krige.rds")
    choc$selectThis[is.na(choc$selectThis)] <- as.factor(ifelse(choc_select_krige$krige_output$var1.pred >= 1.5, 1, 0))

    # Add interpolated data to statewide predictors
    pred$selectThis[pred$study == "choc"] <- choc$selectThis

    # Save predictors
    # saveRDS(pred, file = "../Data/Kriging_outputs/predictors_kriged.rds")


    # Statewide angle transformation
    # Transform angles to 0,90
    ang <- pred %>%
      dplyr::select(angle) %>%
      as.data.frame()  # convert from sf to dataframe

    # Extract and transform angles >90
    ang[which(ang$angle > 90), "angle"] <- 90-abs((ang[which(ang$angle > 90), "angle"]%%180)-90)
    pred$angle <- ang$angle
    any(pred$angle > 90)  # check transformation

    # Save predictors
    # saveRDS(pred, file = "data/predictors_kriged_fix.rds")
    pred <- readRDS(file = "data/predictors_kriged_fix.rds")

    # Update site-specific predictors
    choc <- pred[pred$study == "choc",]
    IRL <- pred[pred$study == "IRL",]
    pens <- pred[pred$study == "pens",]
    tampa <- pred[pred$study == "tampa",]


    ## CATEGORICAL VARS -----

    # Function for interpolating categorical variables
    site_cat <- function(site, var, duplicates.rm = TRUE) {

      # Select variable
      cat.var <- as.data.frame(dplyr::select(site, starts_with(var)))  # automatically selects geometry

      # Convert to spatial object
      cat.var <- sp::SpatialPointsDataFrame(coords = sf::st_coordinates(sf::st_as_sf(cat.var)),
                                            data = cat.var,
                                            proj4string = crs)

      # Locations to krige for
      name <- deparse(substitute(site))
      newdat <- miss_data %>%
        filter(study == name) %>%
        dplyr::select(starts_with(var))
      newdat <- newdat[newdat[[1]] == 1,]

      # Empty list
      krige <- list()

      # Krige for categorical variable (if possible)
      for (i in 1:(ncol(cat.var)-1)) {
        print(paste(i, "out of", ncol(cat.var)-1))  # to track progress
        if (all(cat.var[[i]] == 1)) {
          krige[i] <- list(paste("All identical and equal to 1"),
                           var1.pred = 1)
        } else if (all(cat.var[[i]] == 0)) {
          krige[i] <- list(paste("All identical and equal to 0"),
                           var1.pred = 0)
        } else {
          # Kriging formula
          formula <- as.formula(paste(names(cat.var)[i], " ~ 1"))
          krige[i] <- automap::autoKrige(formula = formula, cat.var,
                                         new_data = sp::SpatialPointsDataFrame(sf::st_coordinates(sf::st_as_sf(newdat)),
                                                                               data = as.data.frame(newdat),
                                                                               proj4string = crs),
                                         remove_duplicates = duplicates.rm, verbose = TRUE)
        }
      }

      # Rename list elements to match categories
      names(krige) <- names(cat.var)[-ncol(cat.var)]

      return(krige)  # kriged output
    }

    # # Example for choc PermStruc variable
    # choc_Perm_krige <- site_cat(choc, "PermStruc", duplicates.rm = FALSE)
    #
    # # Combine all kriging outputs
    # new_perm_choc <- new_perm_choc %>%
    #   mutate(PermStruc_1 = choc_Perm_krige[[1]]$var1.pred,
    #          PermStruc_2 = choc_Perm_krige[[2]]$var1.pred,
    #          PermStruc_3 = choc_Perm_krige[[3]]$var1.pred)
    #
    # for (i in 1:nrow(new_perm_choc)) {
    #   # Select categories with highest probabilities
    #   max_cat <- which(max(c(new_perm_choc$PermStruc_1,
    #                          new_perm_choc$PermStruc_2,
    #                          new_perm_choc$PermStruc_3)))
    #
    #   if (all(new_perm_choc[i,] < 0.5)) {
    #     choc$PermStruc_1[choc$geometry == new_perm_choc$geometry[i]] <- 0
    #   } else if (max_cat == 1) {
    #     choc$PermStruc_1[choc$geometry == new_perm_choc$geometry[i]] <- 1
    #   } else if (max_cat == 2) {
    #     choc$PermStruc_2[choc$geometry == new_perm_choc$geometry[i]] <- 1
    #   } else if (max_cat == 3) {
    #     choc$PermStruc_3[choc$geometry == new_perm_choc$geometry[i]] <- 1
    #   }
    # }
    #
    # # Add to statewide predictors
    # pred$PermStruc_1[pred$study == "choc"] <- choc$PermStruc_1
    # pred$PermStruc_2[pred$study == "choc"] <- choc$PermStruc_2
    # pred$PermStruc_3[pred$study == "choc"] <- choc$PermStruc_3

    ## Kriging returned all NAs for indicator variables (Unable to interpolate)

    ## Updated predictors with spatial interpolation then fed through `pruning_kriging.R` for model selection

## Pruning & Model Selection (`pruning_kriging.R`)

The following script is used to prepare predictor and response variables
for the model selection workflow contained in `BUPD.R` (or
`BUPD_nonparallel.R`). The script generates the following outputs,
though additional outputs can be added as necessary:

-   `"_final_model.rds"`: Contains model summary and slopes for
    predictors
-   `"_final_form.rds"`: Contains final model formula with best AIC
-   `"_odds_ratios.rds"`: Contains odds ratios for predictors
-   `"_average_betas.rds"`: Contains betas retrieved from model
    summaries

To ensure models run without errors, any remaining missing values (NA)
for numerical variables are replaced with the statewide mean (calculated
as the mean across all regional datasets), which are standardized across
studies for consistency.

The output from this script can be used in downstream analyses, as
documented in `MetaAnalysis.md`.

    #############################################
    # GET RESPONSE AND STANDARDIZED PREDICTORS
    #############################################
    resp <- as.data.frame(cbind(state$Response, state$study))
    colnames(resp) <- c("Response", "study")
    # NEW!
    # resp <- data.frame(Response = state$Response)
    resp$Response <- as.factor(resp$Response)
    resp$Response <- ordered(resp$Response)

    # Replace NAs with means for numerical variables
    pred <- pred %>%
      mutate(across(all_of(numerical_vars), ~ ifelse(is.na(.), mean(., na.rm = TRUE), .)))

    # Standardize numeric vars
    pred <- pred %>%
      mutate(across(all_of(numerical_vars), ~ (.-mean(., na.rm = TRUE))/sd(., na.rm = TRUE)))
      
    # List all predictors (AKA column names of known predictors)
    numeric_pred <- pred %>%
      select_if(is.numeric)
    factor_pred <- pred %>%
      select_if(is.factor)
    factor_pred <- factor_pred %>%
      mutate(across(all_of(colnames(factor_pred)), as.character)) %>%
      mutate(across(all_of(colnames(factor_pred)), as.numeric))
    predictors <- colnames(cbind(factor_pred, numeric_pred))
    predictors <- predictors[-5]  # remove SandSpit
    ## Inclusion of SandSpit causes Error in str2lang(x) : <text>:2:0:
    ##                              unexpected end of input 1: Response ~ ^
    
    pred <- pred %>%
      mutate(across(all_of(colnames(factor_pred)), as.character)) %>%
      mutate(across(all_of(colnames(factor_pred)), as.numeric))  # convert factors to numeric

    # Save standardized predictors
    # saveRDS(pred, file = "data/predictors_kriged_standardized.RDS")

    # Filter by study
    resp_choc <- resp %>% filter(study == "choc")
    resp_pens <- resp %>% filter(study == "pens")
    resp_tampa <- resp %>% filter(study == "tampa")
    resp_IRL <- resp %>% filter(study == "IRL")

    pred_choc <- pred %>% filter(study == "choc")
    pred_pens <- pred %>% filter(study == "pens")
    pred_tampa <- pred %>% filter(study == "tampa")
    pred_IRL <- pred %>% filter(study == "IRL")

    ##### CHOSE STUDY HERE #####
    # combine response and pred
    data <- cbind(resp_choc, pred_choc) # choc example

    # Specify a short name of the model
    name <- "choc_non_parallel_fix"
    ############################

    # Define the response variable
    response_var <- "Response"

    study <- data.frame(study = state$study)
    input <- cbind(resp_choc, pred_choc)
    input$SMMv5Def <- NULL
    input$study <- as.factor(input$study)

    # Run build-up/pair-down R scripts
    start_time <- Sys.time()
    source("inst/scripts/BUPD_nonparallel.R")
    end_time <- Sys.time()


    #######################
    # RETRIEVE BETAS
    #######################

    # Betas were retrieved from the model summary for each site
    average_betas <- as.data.frame(summary(final_model)[1])
    colnames(average_betas) <- c("Estimate", "Std. Error", "t value")
    average_betas <- as.matrix(average_betas)

    # Save output
    output_directory <- "data"
    saveRDS(average_betas, file = file.path(output_directory, paste0(name, "_average_betas.rds")))

### References

Cressie, N. (1993) Statistics for spatial data, Wiley, New York.
